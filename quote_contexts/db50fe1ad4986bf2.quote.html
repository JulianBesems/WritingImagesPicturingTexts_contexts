<!doctype html>
<html lang="en"><head><meta charset="utf-8">
<title>Quote Context db50fe1ad4986bf2</title>
<style>
  body{font:14px/1.45 -apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:900px;margin:24px auto;padding:0 16px;color:#222}
  header{display:flex;gap:8px;align-items:center;margin-bottom:16px}
  .pill{padding:2px 8px;border-radius:999px;background:#f2f2f2;border:1px solid #e6e6e6;font-size:12px}
  h2{font-size:16px;margin:16px 0 8px}
  pre{white-space:pre-wrap;background:#fafafa;border:1px dashed #ddd;padding:8px;border-radius:8px}
  ol{margin:8px 0 0 20px}
  li.sel{background:#fff5cc}
  .selected{padding:8px 10px;border-left:4px solid darkorange;background:#fff}
  .muted{color:#666;font-size:12px}
</style>
</head>
<body>
  <header>
    <div class="pill">ctx: db50fe1ad4986bf2</div>
    <div class="pill">origin: <strong style="color:darkorange">zotero</strong></div>
  </header>

  <section>
    <h2>Search text used</h2>
    <pre>Inside this interval, curated collections of multimodal documents are treated as a conceptual counterpart to the 3D architectural model: as a cast that supports multiple readings through its projections (Fig. 3.1:1). Here as a propositional exploration of how this might take form, we are therefore defaulting to the current dominant multi modal relation in computing: Images and Texts. Not because architecture is reducible to them, but because they offer a stringent test case for an architectonic mechanics between modalities.</pre>
  </section>

  <section>
    <h2>Selected</h2>
    <div class="selected">-</div>
  </section>

  <section>
    <h2>All candidates <span class="muted">(right-click the quote in the editor to open this page)</span></h2>
    <ol>
      <li class="sel">-</li>
    </ol>
  </section>
</body></html>
