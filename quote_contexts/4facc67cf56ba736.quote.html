<!doctype html>
<html lang="en"><head><meta charset="utf-8">
<title>Quote Context 4facc67cf56ba736</title>
<style>
  body{font:14px/1.45 -apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:900px;margin:24px auto;padding:0 16px;color:#222}
  header{display:flex;gap:8px;align-items:center;margin-bottom:16px}
  .pill{padding:2px 8px;border-radius:999px;background:#f2f2f2;border:1px solid #e6e6e6;font-size:12px}
  h2{font-size:16px;margin:16px 0 8px}
  pre{white-space:pre-wrap;background:#fafafa;border:1px dashed #ddd;padding:8px;border-radius:8px}
  ol{margin:8px 0 0 20px}
  li.sel{background:#fff5cc}
  .selected{padding:8px 10px;border-left:4px solid magenta;background:#fff}
  .muted{color:#666;font-size:12px}
</style>
</head>
<body>
  <header>
    <div class="pill">ctx: 4facc67cf56ba736</div>
    <div class="pill">origin: <strong style="color:magenta">suggested</strong></div>
  </header>

  <section>
    <h2>Search text used</h2>
    <pre>Given the simple condition that a text editor is bound by text, and that a thesis which is the testing ground for this multi-modal cast is primarily expected within this domain as well, the primary focus of the interaction is mediated by the writing I am presenting here. However as mentioned the other direction from imagery to text will be explored in one of the experimental sub-chapters in chapter 4, although this will be done partially outside of the text editor. Therefore we will first present the active mediations that are implemented within the WIPT editor, and at the end of this chapter we will briefly showcase the nature of the inverse direction. Figure 3.6:1 - Screenshot of the text editor, showing the section of this chapter, with the config buttons at the top of the section, next to it are the thumbnails of dropped in pdfs, the dropdown menu for the image projection method at the bottom, targeting slider, and the editor window to the right. First a short note on the way in which the frontend of the editor is connected to the elements, screens and material explained above. The entire editor is interacted with through a web-interface, currently run on a localhost. Everything is written in the Markdown editing format, typed into a pop-up window, which in turn gets rendered as a formatted text in the main window. The main window is broken up into separate sections that can be selected to edit, generally meant to contain a chapter or subchapter per section, clicking the section loads the content markdown text into the editor pop-up window. Additionally the section has 3 buttons at the top: bookConfig, saveConfig and loadConfig, which are there to set up the input book references through which the books are selected that will make up the paragraph collection for that section. The input books are provided by simply dropping a pdf document onto the section. The combination of these dropped in pdf&#x27;s constitutes a situated cast, a personalised perspective on the public corpus of text specific to the writing of that section. Once a configuration has been loaded, two moveable containers show up in the main window, one containing a red paragraph that is the top result from projecting the content being written at that moment onto the paragraphs of that section&#x27;s books, the other contains a magenta paragraph which is the top result through the suggested paragraph based on the aforementioned writing. Clicking either opens another window containing the total list of 10-20 results depending on the configuration setting, which are also the alternative sentences that are visible when clicking one of the included red or magenta citations throughout this thesis. This projection of both suggestion and writing is initiated after typing stops for 2 seconds. The writer engages in a constantly present back and forth with the editor as it replies in a situated context.

<em>As the writer navigates this web-based interface, the editor&#x27;s responses are constantly updated, allowing for a seamless integration of writing and feedback. The editor&#x27;s situated context is further reinforced by the ability to select and load different books, which not only provide a rich source of paragraphs but also serve as a backdrop for the writer&#x27;s creative process. The interaction between the writer and the editor becomes a dynamic dance, with the editor&#x27;s suggestions and the writer&#x27;s input constantly informing and refining the writing process. As we explore this interactive environment in more detail, it is essential to recognize the crucial role that the WIPT editor plays in facilitating this creative dialogue.  In the following sections, we will delve deeper into the specific features and functionalities of the WIPT editor, examining how it supports the writer in generating high-quality writing.</em></pre>
  </section>

  <section>
    <h2>Selected</h2>
    <div class="selected">the task-artifact model (Carroll &amp; Rosson, 1992), task analysis (e. g. , Pinelle, et al. , 2003), and the reference task model Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. Interaction 23 (Whittaker, et al. , 1997). It also takes into account the models developed in related areas of research, including relevant CSCW literature. The literature review also shows a number of workplace interaction models (e. g. , Suchman 1995, Whittaker et al.[Wiberg, Mikael *Interactive Textures for Architecture and Landscaping: Digital Elements and Technologies*. Engineering Science Reference, 2010.]</div>
  </section>

  <section>
    <h2>All candidates <span class="muted">(right-click the quote in the editor to open this page)</span></h2>
    <ol>
      <li>&quot;the task-artifact model (Carroll &amp; Rosson, 1992), task analysis (e. g. , Pinelle, et al. , 2003), and the reference task model Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. Interaction 23 (Whittaker, et al. , 1997). It also takes into account the models developed in related areas of research, including relevant CSCW literature. The literature review also shows a number of workplace interaction models (e. g. , Suchman 1995, Whittaker et al.&quot;[Wiberg, Mikael *Interactive Textures for Architecture and Landscaping: Digital Elements and Technologies*. Engineering Science Reference, 2010.]</li>
<li>&quot;In those sessions the process is modeled by an expert using an software tool. Participants can see how the process evolves and participate by providing input. We argue that TBPM fosters another level of participation because the participants do not have to channel their input through a tool operator. Also, the direct interaction with the process creates a different notion of responsibility for the result. Nevertheless, Persson’s recommendations [12] serve as a good guideline for group modeling sessions.&quot;[Lindberg, Tilmann, Christoph Meinel, Ralf Wagner (auth.), Christoph Meinel, Larry Leifer, and Hasso Plattner (eds.) *Design Thinking: Understand – Improve – Apply*. Springer-Verlag Berlin Heidelberg, 2011.]</li>
<li>&quot;The twelve factors are: affordance, cognitive offloading, constraints, distance, epistemic appropriateness, feedback, flexibility, flow, focus, involvement, scaffolding, and transition (for definitions, see Table 16. 1). As in the case of the interaction framework, not only are these factors abstractions and can have many different instantiations, but also the list of the interactivity factors is not exhaustive and can be expanded. Table 16. 1 The three interaction design frameworks Conversing Manipulating Navigating Animating Annotating Chunking Composing Cutting Task-based Interaction Framework Basic Interactions Filtering Fragmenting Probing Rearranging Repicturing Scoping Searching Descriptions Talking to a visualization using symbolic, lexical expressions or commands Handling a visualization using a pointing cursor Moving on, over, or through a visualization Generating movement within a visualization Augmenting a visualization by placing marks on it Grouping a number of similar or related, but disjoined, visual elements Putting together separate visual elements to form a new visualization Removing unwanted or unnecessary portions of a visualization Showing, hiding, or transforming a selected subset of visual elements of a visualization based on certain criteria Breaking a visualization into its elemental parts Focusing on or drilling into some aspect, property, or component of a visualization for further analysis Changing the spatial position and/or direction of elements of a visualization Displaying a visualization in an alternative manner Changing the degree to which a visualization is visually constructed/deconstructed by adjusting its field of view Seeking out the existence of or position of specific features, elements or structures within a visualization (continued) 16 Interactive Mathematical Visualizations 349 Table 16. 1 (continued) Factors Descriptions Affordance Provision of interface cues to advertise possible interactions with a visualization Provision of interactions that can shoulder the load of some cognitive processes for the user, such as how a visualization changes from one form to another Restriction of possible interactions with a visualization to canalize and guide the user’s cognitive processes Degree of difficulty in understanding how to act upon a visualization and to interpret its subsequent response (types: semantic, articulatory, conceptual, presentation) Suitability and harmony of interactions in supporting exploration of a visualization Exchange of information and the direction of communication between the user and a visualization Range and availability of interactive choices and options available to the user Duration of interaction with a visualization in time and its effects on the user’s perception of the relationship between cause and effect (types: continuous, discrete) Locus of the user’s attention during interaction with the visualization (types: direct, indirect) Degree of users’ engagement with and contribution to the information content of a visualization allowed by the available interactions Provision of interactions to cognitively support and augment the user’s reasoning and understanding of the encoded information in a visualization Communication of visual changes of a visualization (types: stacked, distributed) Cognitive offloading Constraints Interactivity Framework Distance Epistemic appropriateness Feedback Flexibility Flow Focus Involvement Scaffolding Macro Interaction Framework Transition Macro Interactions Access-based Annotation-based Construction-based Combination-based 16. 3. 3 Descriptions Accessing stored, available visualizations Adding meta-information to existing visualizations Constructing new visualizations Combining two or more of access, annotation, or construction operations together Macro-Level Interaction Framework Sedig and Liang [24] have developed a framework which abstracts and characterizes all interactive visualization tools according to their macroscopic user-information interaction operations.&quot;[Zudilova-Seinstra, Elena, Tony Adriaansen, Robert van Liere (auth.), Robert Liere, Tony Adriaansen, and Elena Zudilova-Seinstra (eds.) *Trends in Interactive Visualization: State-of-the-Art Survey*. Springer-Verlag London, 2009.]</li>
<li>&quot;This audit captured the key user interaction requirements across a number of scientific applications and clearly 6 Gaining Greater Insight Through Interactive Visualization 129 indicated that the associated user interaction process is complex and involved. It necessitated a number of stages (or steps) from ‘pre’ job submission preparation through to the more highly interactive stages of interactive visualization. A key user interaction requirement emerging from the audit was the need to reduce the time delay between user input and the corresponding output from the simulation.&quot;[Zudilova-Seinstra, Elena, Tony Adriaansen, Robert van Liere (auth.), Robert Liere, Tony Adriaansen, and Elena Zudilova-Seinstra (eds.) *Trends in Interactive Visualization: State-of-the-Art Survey*. Springer-Verlag London, 2009.]</li>
<li>&quot;Any analysis focusing on a single communication tool or homogeneous collaboration environment can therefore only comprise fractional and isolated parts of the information handling process. In order to complete this picture, capabilities to centrally monitor a broader range of distributed and concurrent communication activities over multiple channels are needed. Critical system requirements also stem from the complexities in design collaboration environments, which are increasingly distributed across multiple sites.&quot;[Lindberg, Tilmann, Christoph Meinel, Ralf Wagner (auth.), Christoph Meinel, Larry Leifer, and Hasso Plattner (eds.) *Design Thinking: Understand – Improve – Apply*. Springer-Verlag Berlin Heidelberg, 2011.]</li>
<li>&quot;Gregor Gabrysiak’s master’s thesis, Modeling and Simulation of Reusable Collaborations for Embedded Systems with Dynamic Structures, 2009. 5 228 G. Gabrysiak et al. Author Write Article Reviewer Initial Research Incorporate Corrections Review Article Corrections Order Article Admin Publisher . DOC File Printed Article Approve for Publication . DOC File Insert Article into CMS Fig. 6 An initially synthesized process based on insights from interviews 3. 4. 2 Modeling the Insights Based on these interviews, design thinkers have to identify activities, a preliminary causal order of activities, abstract roles these activities are assigned to, and scenarios with interactions.&quot;[Lindberg, Tilmann, Christoph Meinel, Ralf Wagner (auth.), Christoph Meinel, Larry Leifer, and Hasso Plattner (eds.) *Design Thinking: Understand – Improve – Apply*. Springer-Verlag Berlin Heidelberg, 2011.]</li>
<li>&quot;In typical participatory design projects the idea of involving “communities of practice” (Wenger, 1998) has been a popular topic. Through close collaboration with the users, and through a better understanding of the users context the assumption is that interaction designers can build better systems to support their everyday activities. However, as the digital scale from the device to the environment we also need to bring in more people, or at least several different competences at the development side of the process.&quot;[Wiberg, Mikael *Interactive Textures for Architecture and Landscaping: Digital Elements and Technologies*. Engineering Science Reference, 2010.]</li>
<li>&quot;Continuous improvements in computers’ processing power and graphics capabilities have made it possible to incorporate a wide range of IV techniques in most computing application domains, including medicine, engineering, business and science. National laboratories have already embraced this technology and as IV penetrates the market, many institutions are using it to drive scientific discovery and competitive advantage [26]. This chapter provides an overview of Interactive Visualization. First, we introduce a basic model of the IV process and discuss four ways how the user may interact with the visualized data.&quot;[Zudilova-Seinstra, Elena, Tony Adriaansen, Robert van Liere (auth.), Robert Liere, Tony Adriaansen, and Elena Zudilova-Seinstra (eds.) *Trends in Interactive Visualization: State-of-the-Art Survey*. Springer-Verlag London, 2009.]</li>
<li>&quot;Second, going along with this, Derrida’s ultratranscendental concepts bleed into one another. As we have seen, one cannot speak of ‘différance’ without at the same time invoking ‘trace’, ‘archi-writing’ and ‘supplementarity’. However, this section is designed to fulfil the role that a glossary would Study Aids 207 typically fulfil, providing concise descriptions of the central concepts of the book, in order to enable the convenience of quick reference on the part of the reader. Archi-writing (writing) This is one of those terms that only explicitly appears in Voice and Phenomenon one time (VP, p. 73/85/95), and it occurs more frequently in Of Grammatology.&quot;[Cisney, Vernon W. *Derrida&#x27;s Voice and Phenomenon*. Edinburgh University Press, 2014.]</li>
<li>&quot;The advanced features also give rise to a high degree of expressiveness of the virtual brush that the user can comfortably manipulate. In this chapter, we describe the architecture of the various components involved in a computational solution to digital Chinese painting and calligraphy. The four key elements constituting the digital painting and calligraphy process are painter, brush, ink and paper. Their interaction is illustrated in Fig. 3. 1. 3. 2 Background Virtual brush is an important tool for interactive painting [Str86, HH90, HLW93, HL94, SABS94, ABL95, SN99, Pix00, WI00, BSLM01, KMM+ 02, XTLP02, CT02].&quot;[Xu, Songhua, Francis C.M. Lau, and Yunhe Pan *A Computational Approach to Digital Chinese Painting and Calligraphy*. Springer, 2009.]</li>
<li>&quot;For instance, in the paper “Conceptdriven Interaction Design Research” the authors Stolterman &amp; Wiberg (2010) argues that in the field of interaction design people do not only develop systems based on a human-centered design approach from problem identification to product in a similar process as criticized by Margolis &amp; Robinson (2007). Instead, it is a common approach to also follow a concept-driven process in which guiding theoretical concepts, like the notion of “interactive textures” work as a vision and raw model for the practical efforts made to realize such installations.&quot;[Wiberg, Mikael *Interactive Textures for Architecture and Landscaping: Digital Elements and Technologies*. Engineering Science Reference, 2010.]</li>
<li>&quot;Qian [Qia86] argued that the synthesis process (using qualitative or quantitative approaches) is an important aspect of brain activities. Hall [Hal89] comprehensively surveyed the computational eﬀorts to simulate analogous reasoning. Kapur [KM88] explored the application of artiﬁcial intelligence in geometrical reasoning. Pan et al. [Pan93, XP95, LPJ96, PG96, GP96, ZP97] has researched modeling visual information for intelligent computer-aided design.&quot;[Xu, Songhua, Francis C.M. Lau, and Yunhe Pan *A Computational Approach to Digital Chinese Painting and Calligraphy*. Springer, 2009.]</li>
<li>&quot;3. 1 Process Recipe As desclibed in Section 2, the process recipe is stored in COB in the STEPS module. In order to permit interactive modification of the recipe, the framework must provide a process editor. This editor is used to specify all process and device simulation, parameter extraction, and measurement steps. PREDITOR uses a TklTcl-based process editor. When PREOITOR is initialized, the editor quelies the COB server for the list of supported simulation steps, the required parameter fields, and default values.&quot;[Lloyd, P., C. C. McAndrew, M. J. McLennan, S. Nassif, K. Singhal (auth.), Dipl.-Ing. Franz Fasching, Dipl.-Ing. Stefan Halama, and Univ.-Prof. Dipl.-Ing. Dr. Siegfried Selberherr (eds.) *Technology CAD Systems*. Springer-Verlag Wien, 1993.]</li>
<li>&quot;So long as one is explicit about which sort of methodology one is pursuing, what rules determine the admissibility of various elements into the context that provides the conceptual perspective from which one reads a text, assessments of the legitimacy of one approach or another should give way to assessments of their hermeneutic fruitfulness: the sort of understanding they yleld. I opened the discussion of methodology in this section with a musical trope: the image of bebop historiography,in which a melody is treated as an occasion for improvisation on its chord structure.&quot;[Brandom, Robert B. *Tales of the Mighty Dead: Historical Essays in the Metaphysics of Intentionality*. Harvard University Press, 2002.]</li>
<li>&quot;In fact, it is the objective of CFI to promote the role of commercial vendors as providers of tools that comply with the standards. One prototype software integration project at Stanford, SEWB (Simulation Engineering Workbench) [15], illlustrates how vendor tools and the standardization of information models (including SWR) provide an exciting testbed for TCAD development and innovation. Work in the area of scientific visualization demonstrates how the same plug-and-play approach leverages exciting new development outside the direct scope of TCAD.&quot;[Lloyd, P., C. C. McAndrew, M. J. McLennan, S. Nassif, K. Singhal (auth.), Dipl.-Ing. Franz Fasching, Dipl.-Ing. Stefan Halama, and Univ.-Prof. Dipl.-Ing. Dr. Siegfried Selberherr (eds.) *Technology CAD Systems*. Springer-Verlag Wien, 1993.]</li>
    </ol>
  </section>
</body></html>
