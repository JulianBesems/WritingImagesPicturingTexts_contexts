<!doctype html>
<html lang="en"><head><meta charset="utf-8">
<title>Quote Context 49042741a3a0f186</title>
<style>
  body{font:14px/1.45 -apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:900px;margin:24px auto;padding:0 16px;color:#222}
  header{display:flex;gap:8px;align-items:center;margin-bottom:16px}
  .pill{padding:2px 8px;border-radius:999px;background:#f2f2f2;border:1px solid #e6e6e6;font-size:12px}
  h2{font-size:16px;margin:16px 0 8px}
  pre{white-space:pre-wrap;background:#fafafa;border:1px dashed #ddd;padding:8px;border-radius:8px}
  ol{margin:8px 0 0 20px}
  li.sel{background:#fff5cc}
  .selected{padding:8px 10px;border-left:4px solid red;background:#fff}
  .muted{color:#666;font-size:12px}
</style>
</head>
<body>
  <header>
    <div class="pill">ctx: 49042741a3a0f186</div>
    <div class="pill">origin: <strong style="color:red">searched</strong></div>
  </header>

  <section>
    <h2>Search text used</h2>
    <pre>At the same time, the scope of the thesis is explicitly instrumental rather than model-inventive. Current ML developments have culminated in models that can transform input data to related information, both between domains (e.g. text to image) and within domains (e.g. text to text). These developments are of evident relevance here because they enable continuous interaction. Because of the high complexity, requirement of resources, and the reliance on enormous scale of data of such models, the thesis does not attempt to extend their computational architectures, nor retrain them; instead it focuses on using and connecting existing technologies, using small scale datasets to curate particular kinds of interactions. Their original setup is used, connected, and probed in ways that support the thesis’s architectonic propositions about projection, proportion, and heterogeneity. Their rapid evolution is therefore addressed as context and constraint: it informs what can be staged, but does not determine what counts as an architectural outcome.</pre>
  </section>

  <section>
    <h2>Selected</h2>
    <div class="selected">Such structure yields complexity beyond that typically shown in co-speech gestures or the binding of text with individual images (Cohn, 2013a). This work seeks to characterize such complex multimodal interactions by expanding on Jackendoff’s (2002) parallel architecture for language. Here, focus will be placed on how grammar and meaning coalesce in multimodal interactions, extending beyond the semantic taxonomies typically discussed about text–image relations (e. g. , Kress, 2009; Martinec &amp; Salway, 2005; McCloud, 1993; Royce, 2007).[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</div>
  </section>

  <section>
    <h2>All candidates <span class="muted">(right-click the quote in the editor to open this page)</span></h2>
    <ol>
      <li>&quot;Such structure yields complexity beyond that typically shown in co-speech gestures or the binding of text with individual images (Cohn, 2013a). This work seeks to characterize such complex multimodal interactions by expanding on Jackendoff’s (2002) parallel architecture for language. Here, focus will be placed on how grammar and meaning coalesce in multimodal interactions, extending beyond the semantic taxonomies typically discussed about text–image relations (e. g. , Kress, 2009; Martinec &amp; Salway, 2005; McCloud, 1993; Royce, 2007).&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;While not stated explicitly, McCloud’s overall approach implies that panels create a ‘‘text–image unit,” which then engages in a semantic relationship with each subsequent text–image unit. Though this model provides a foundation for varying text– image relationships, McCloud’s approach (and others) cannot account for certain contrasts between multimodal interactions. Consider Fig.&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;This notion can be extended to many text–image relations as well (Cohn, 2013a), where bundled text and image form a coherent message within a single panel that progresses to subsequent units (e. g. , McCloud, 1993). In both cases, modalities may make a semantic correspondence in relating to common conceptual information (McNeill, 1992), but the visual-graphic domain does not use temporal correspondence as in co-speech gesture (i. e. , association from occurring at the same time) unless it is produced in real time interactions (e. g. , Green, 2014).&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;12 4 DEDRE GENTNER AND BRIAN BOWDLE Notes 1 2 3 4 5 6 Although structure-mapping is best known as a theory of analogy, metaphor has been a focus of the work from its inception (e. g. , Gentner, 1982). Structure-mapping theory assumes the existence of structured representations made up of entities and their attributes, functions that map entities to dimensions or to other entities, relations between objects, and higherorder relations between relations. This discussion is taken chiefly from structure-mapping theory (Gentner, 1983 ; Gentner &amp; Markman, 1997) and its computational model, SME, the structure-mapping engine (Falkenhainer, Forbus, &amp; Gentner, 1989; Forbus, Gentner, &amp; Law, 1995 ; Forbus &amp; Oblinger, 1990).&quot;[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]</li>
<li>&quot;This approach can instead involve “metaphorizing” the literal sentences in the relevant discourse segment: translating the information in them into sourcedomain terms. We present this possibility as a potentially fruitful topic for future research into metaphor. Conclusion AI is not just about the engineering of “intelligent” artefacts for useful purposes but also about mapping out the space of possible principles and mechanisms of cognition, whether artificial or natural.&quot;[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]</li>
<li>&quot;Learning more precise semantic structures, typically involving selectional restrictions, is the aim of much research around information extraction: porting an IE system to a new domain means acquiring again local patterns or semantic grammars for identifying speciﬁc information items. Among these works are Riloﬀ &amp; Jones  Benoît Habert and Pierre Zweigenbaum (1999), Roark &amp; Charniak (1998), presented above.&quot;[(Ed.), Bruce E. Nevin, and Stephen M. Johnson (Ed.) *The Legacy of Zellig Harris: Language and Information into the 21st Century, Vol. 2: Mathematics and Computability of Language*. Amsterdam; Philadelphia: John Benjamins Publishing Company, 2002.]</li>
<li>&quot;This work raises Foreword xvii intriguing issues about the relation between information and language. In contrast with text analysis, text generation must focus on whole texts instead of single sentences. Kittredge describes distributional analysis carried out at the sentence level, which assigns sentences to classes. Members of a class are informationally equivalent; each can be an answer to the same question. This approach is reminiscent of the discourse dependencies invoked by Pereira in the ﬁrst section of this book.&quot;[(Ed.), Bruce E. Nevin, and Stephen M. Johnson (Ed.) *The Legacy of Zellig Harris: Language and Information into the 21st Century, Vol. 2: Mathematics and Computability of Language*. Amsterdam; Philadelphia: John Benjamins Publishing Company, 2002.]</li>
<li>&quot;The Meaning-Text stratiﬁcational model of language (cf. Mel’čuk &amp; Pertsov 1987) was used for sentence realization, acting on sentence speciﬁcations that were output from an integrated module that interleaved content determination and text planning. 10 One of the signiﬁcant issues in generating statistical summaries of this type is the planning of their global text structure.&quot;[(Ed.), Bruce E. Nevin, and Stephen M. Johnson (Ed.) *The Legacy of Zellig Harris: Language and Information into the 21st Century, Vol. 2: Mathematics and Computability of Language*. Amsterdam; Philadelphia: John Benjamins Publishing Company, 2002.]</li>
<li>&quot;In the desired framework, visual intelligent systems should be able to reconstruct a “story” from basic information, blending relevant visual data with common-sense knowledge into a unifying conceptual pattern. Adopting an architectural perspective, implementing this capability would require three different strata of information elaboration: basic optical features (low-level), object detection (mid-level) and event classification (high-level). In this contribution we focus on high-level mechanisms and contents, namely the core visual intelligence as opposed to state-of-the-art machine vision.&quot;[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]</li>
<li>&quot;9. 2 9. 2 EMPIRICAL ILLUSTRATIONS EMPIRICAL ILLUSTRATIONS apwas used to illustrate problems with fundamental aspects of conventional apThe Hungarian data was proaches to linguistic analysis and the ability of the dynamic, inferential approach that I advocate to produce highly explanatory alternative accounts of linguistic data. On one level, the rather ad hoc nature of many aspects of conventional syntactico-semantic 3)-multiple abstract accounts of the Hungarian &#x27;focus position&#x27; (as briefly reviewed in Chapter 3)—multiple syntactic projections to deal with different different expressions sharing one surface position, discrete sesemantic operators posited to account for each possible interpretive effect, and so on—gives on-gives good reason on its own own to question the theory and the methodology applied, but I also provided more concrete and decisive demonstrations of how how the basis of conventional approaches leads to problems in dealing with the data.&quot;[Wedgwood, Daniel *Particulate Colloids*. Elsevier Science, 2005.]</li>
<li>&quot;The nature of this LF process is unclear; Herburger (2000, 42,47) recognises that there is no syntactic evidence for it. It would presumably have to be sensitive to prosody as well as to syntactic structure as such-or such—or involve some form of of prosodically informed informed syntactic representation about which Herburger is inexplicit—since inexplicit-since both may be involved in the signalling of information information structure. In any case, it leaves her analysis with the same problems that attend any attempt to encode focus directly, as discussed in previous chapters: it does no more than other &#x27;structured meaning&#x27; approaches to address issues of encoding versus inference in this necessarily context-related domain (Herburger&#x27;s only concession to the role of context is a &#x27;contextual predicate&#x27; that is present in every propositional representation; a strategy that is very likely to be rendered redundant by independently justified justified pragmatic theory, according to the arguments of Chapter 1. significant departure from other &#x27;strucIn this sense, Herburger&#x27;s proposals do not represent a significant tured meaning&#x27; approaches (von Stechow 1991a), at least in relation to my aims in this book.&quot;[Wedgwood, Daniel *Particulate Colloids*. Elsevier Science, 2005.]</li>
<li>&quot;194 Alistair Knott, Jon Oberlander, Michael O&#x27;DonneU and Chris Mellish 7· Discussion This paper has discussed a nwnber of problems with RST&#x27;s theories of span structure and relation semantics which stem from its use of the relation OBJECT-ATTRIBUTE EL\BORATION. It argues that a better account of text coherence can be developed by abandoning this relation, and allowing that the metaphor of &#x27;relations between propositions&#x27; only provides a partial account of text coherence. A new account of coherence is put forward in which a model of relations is supplemented with a entity-based model of focus structure.&quot;[Sanders, Ted, Joost Schilperoord, and Wilbert Spooren *Text representation: linguistic and psycholinguistic aspects*. John Benjamins Publishing Company, 2001.]</li>
<li>&quot;Martin (1992) has argued that the line drawn between structural and non-structural resources sometimes unnecessarily classiﬁes into diﬀerent categories resources that construe the same semantic motif at the level of discourse, failing to provide a coherent framework for discourse analysis. Therefore, our revised model (see Figure 17. 1) adopts Martin’s (1992) more elaborate language model, which, by proposing an opposition between grammar and discourse semantics, provides a more powerful tool to analyse text-oriented resources for making meanings.&quot;[Webster, Jonathan J., and Xuanwei Peng (eds.) *Applying Systemic Functional Linguistics: The State of the Art in China Today*. Bloomsbury Academic, 2017.]</li>
<li>&quot;Finally in this section, we may note briefly a recent development, which implements Leech&#x27;s principle of the separability of text and annotation - standoff annotation. In a version of this, Thompson (1997) has used Extensible Markup Language (xml) (a restricted, but conformant, form of sgml) to annotate texts in such a way that the annotation is stored separately from the text itself. The text has within it the most basic level of encoding - for example, sequential numbers of words in the text. The separate annotation then makes use of this information to associate items of annotation with specific words or stretches of words within the text.&quot;[McEnery, Tony, and Andrew Wilson *Corpus linguistics : an introduction*. 2nd ed. Edinburgh: Edinburgh U., 2001.]</li>
<li>&quot;The VERL approach does not refer to large–scale domain ontologies or to acknowledged patterns to provide a structure to the event models. Ballan et al. use the hierarchical linguistic relations over lexical entries encoded in WordNet to learn and refine rules that detect complex events from simple ones [3]. An ontology-based approach to the detection and annotation of events is video is pursued also by the 116 M. Cataldi et al. Mind’s Eye project [10]. In this work, the events detected in video are described as “verbs”, described in terms of a spatial model of motion.&quot;[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]</li>
    </ol>
  </section>
</body></html>
