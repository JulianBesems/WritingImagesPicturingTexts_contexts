{"created_at": 1766161186.504371, "confirmed": true, "origin": "searched", "search_input": "Understanding this as a structural condition rather than a failure and approaching it from an architectural stance offers the opportunity to view the multimodal gap not as a shortcoming to be overcome, but a computational phenomenon in reflecting the non-commensurability of modes. This opens a productive terrain for architectural experimentation, in which computation is not tasked with resolution or translation, but with sustaining resonant disjunctions. Returning to Foucault, his invocation of similitude, distinct from resemblance, is particularly relevant: *\u201cSimilitude multiplies different affirmations, which dance together, tilting and tumbling over one another\u201d*. Unlike resemblance, which depends on a model to be matched, similitude enables a relation without identity. In computational terms, this resonates with the non-bijective, probabilistic relations staged by machine learning: they do not secure what is, but suggest what might be proximate. This idea mirrors the non-aligned multimodal relations in architecture, where images, drawings, and texts exist in a field of conceptual adjacency. In Foucault\u2019s terms, what multimodal ML collapses into descriptive coherence, architectonically this must instead be sustained as speculative simultaneity. Like Ishigami suggests: *\u201cRationality may be less about a simple one-to-one coincidence of function and form and more about the linking of new relationships amid endless, fathomless complexity. Amid the whole, such relationships are always unstable, and engaged in a rocky search for stability.\u201d*", "suggested_query": "lature of the encoding process is crucial for grasping the implications of using machine learning in domain-specific contexts. The apparatus of discernment, which is embodied in the model's architecture and training data, will always introduce a level of bias and partiality, which can have far-reaching consequences for the interpretation and application of the encoded knowledge. This raises important questions about the role of the modeler in shaping the encoding process and the need for transparency and accountability in the development and deployment of machine learning models.", "suggest_context": "2.5 ARCHITECTONIC OBSTACLE The use of machine learning to encode the objects of domains entails that the model is embedded within the domain as much as the objects it encodes. Encoding is therefore never simply the extraction of properties from the thing itself, but the production of differences through a particular apparatus of discernment. In Hegels Observing Reason the topic of Differentiae corresponds to relevant questions as to how we shall relate to the ordered sets of information that are curated by machine learning and the encoding of these objects into vectors as to distinguish them from each other. The \"features\", as the dimensions of these vectors are often referred to, behave in similar fashion to the differentiae, in that they certainly have an essential connection to the object it encodes, however they are as much and possibly to a larger extent a characteristic of the model which makes this encoding: its training, priors, and operative constraints. In accordance as to how the differentiae are essentially connected to the cognition which discerns them. The obstacle is therefore not only that domains differ, but that the very means by which they are made comparable is itself situated and partial. Understanding this as a structura"}