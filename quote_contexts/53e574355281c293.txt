Created: 2025-12-18 22:56:19
Origin: suggested
Selected: In these cases, expressing the location in text rather than images may allow for a more economical message (less panels), but may lead the content of each domain to convey different aspects of meaning, and thereby require the integration of novel information across multiple sources (e. g. , Fauconnier & Turner, 2002). A related process occurs in the substitutive example in Fig. 7b, since the Peak is represented by text instead of an image. Other examples of absorption are discussed at length by Stainbrook (2003, 2015) who describes how surface cohesive relations between images and text contribute toward a holistic mental model of a multimodal discourse (e. g. , van Dijk & Kintsch, 1983), and comparable notions are echoed in Painter et al. ’s (2012) discussion of text or images ‘‘committing” different amounts to a global meaning.[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

--- Context List ---
01. "Contrasting, for example, record and circle, we notice that circle is part of the shape information in record, which relies, however, on knowledge explaining sound storage (in varying degrees of detail), while nothing (beyond mere geometry) is explained by circle. For almost trivial reasons, the distinction of rich and spare concepts relates to (but is not identical with) the distinction between extrinsic and intrinsic spatial concepts, as opposed to strictly spatial concepts."[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]

02. "In these cases, expressing the location in text rather than images may allow for a more economical message (less panels), but may lead the content of each domain to convey different aspects of meaning, and thereby require the integration of novel information across multiple sources (e. g. , Fauconnier & Turner, 2002). A related process occurs in the substitutive example in Fig. 7b, since the Peak is represented by text instead of an image. Other examples of absorption are discussed at length by Stainbrook (2003, 2015) who describes how surface cohesive relations between images and text contribute toward a holistic mental model of a multimodal discourse (e. g. , van Dijk & Kintsch, 1983), and comparable notions are echoed in Painter et al. ’s (2012) discussion of text or images ‘‘committing” different amounts to a global meaning."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

03. "Conceptual representation of spatial structure provides, among other things, more abstract schemata specifying the dimensionality of objects and situations, the axes and frames of reference of their location, and metrical scales with respect to which size is determined. 3. Linguistic knowledge or I-language interfaces with conceptual structure, recruiting configurations of it by basic components of semantic form, where strictly spatial concepts are to be identified as configurations that interpret elements of SF by exclusively spatial conditions on objects and situations."[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]

04. "However, visual narratives, like those in comics, provide an interesting challenge to multimodal communication because the words and/or images can guide the overall meaning, and both modalities can appear in complicated ‘‘grammatical” sequences: sentences use a syntactic structure and sequential images use a narrative structure. These dual structures create complexity beyond those typically addressed by theories of multimodality where only a single form uses combinatorial structure, and also poses challenges for models of the linguistic system that focus on single modalities."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

05. "Such structure yields complexity beyond that typically shown in co-speech gestures or the binding of text with individual images (Cohn, 2013a). This work seeks to characterize such complex multimodal interactions by expanding on Jackendoff’s (2002) parallel architecture for language. Here, focus will be placed on how grammar and meaning coalesce in multimodal interactions, extending beyond the semantic taxonomies typically discussed about text–image relations (e. g. , Kress, 2009; Martinec & Salway, 2005; McCloud, 1993; Royce, 2007)."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

06. "Nevertheless, multimodal texts pose challenges to this notion, as the architecture of a multimodal text consists of several sets of components, which means that contrast and comparison across modes have to be included in stylisticians’ agendas to ﬁnd out foregrounding across modes. In fact, studies on intersemiotic relations in multimodal discourse analysis have proposed several terms to account for multimodal construal of meaning in multimodal texts: namely, “resemioticization” (Iedema 2003: 30), “multiplication of meaning” (Lemke 1998), “semiotic metaphor” (O’Halloran 1999), and “translation” (Kress and van Leeuwen 2006: 78)."[Webster, Jonathan J., and Xuanwei Peng (eds.) *Applying Systemic Functional Linguistics: The State of the Art in China Today*. Bloomsbury Academic, 2017.]

07. "In the desired framework, visual intelligent systems should be able to reconstruct a “story” from basic information, blending relevant visual data with common-sense knowledge into a unifying conceptual pattern. Adopting an architectural perspective, implementing this capability would require three different strata of information elaboration: basic optical features (low-level), object detection (mid-level) and event classification (high-level). In this contribution we focus on high-level mechanisms and contents, namely the core visual intelligence as opposed to state-of-the-art machine vision."[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]

08. "12 4 DEDRE GENTNER AND BRIAN BOWDLE Notes 1 2 3 4 5 6 Although structure-mapping is best known as a theory of analogy, metaphor has been a focus of the work from its inception (e. g. , Gentner, 1982). Structure-mapping theory assumes the existence of structured representations made up of entities and their attributes, functions that map entities to dimensions or to other entities, relations between objects, and higherorder relations between relations. This discussion is taken chiefly from structure-mapping theory (Gentner, 1983 ; Gentner & Markman, 1997) and its computational model, SME, the structure-mapping engine (Falkenhainer, Forbus, & Gentner, 1989; Forbus, Gentner, & Law, 1995 ; Forbus & Oblinger, 1990)."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

09. "According to this theory, sequences of musical events produce brain maps that can be correlated with brain maps produced by other modalities (including vision, taste, and proprioception); these correlations then operate as symbols to form the basis for conceptual knowledge. The array of perceptual symbols (or image schemata) that may be used to structure a given relationship is potentially quite extensive; cultural knowledge provides one constraint on which structures are chosen."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

10. "However, as discussed later, linguistic metaphor as a whole fits as a category within the framework of general fictivity. General fictivity can serve as the superordinate framework because, among other reasons, its concepts and terms can apply as readily to visual representations as to linguistic ones, whereas metaphor theory is cast in concepts and terms more suitable for language alone. Using the perspective and methods of cognitive linguistics, the present study of fictive motion is based in language, but extends out from there to considerations of visual perception."[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]

11. "Instead, a whole analogical structure must be generated that may have many different correspondences and alignments. 1 There are models of analogy making that can deal with complex structures, for example, like mapping the solar system into atomic structure. Such models (e. g. , Forbus, Gentner, & Law, 1995 ; Hummel & Holyoak, 1997) can perform more complex mappings than the present model. However, because they rely on hand-coded propositional knowledge representations, they circumvent an essential component of the comprehension process, the construction of the problem- 141 relevant knowledge representation, which is the focus of the present approach."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

12. "Vice versa, “verbal metaphor itself often elicits references to visual, aural, tactile, and olfactory experiences. ” From the point of view of language use this suggests that there is perhaps a functional link between metaphoric structure and the format of a “subject’s encyclopedia. ” As Eco puts it, “metaphors are produced solely on the basis of a rich cultural framework. ”14 A directional theory of meaning welcomes this kind of analysis because it draws our attention to the question of the linking procedures which we are forced to assume exist between verbal and non-verbal signification."[Ruthrof, Horst *Pandora and Occam: on the limits of language and literature*. Routledge, 2017.]

13. "The next sections present the Cognitive Engine, an integrated artificial system whose architectural characteristics, operational capabilities and knowledge resources are designed to approximate the cognitive machinery of visual intelligence. 8. 3 Making Sense of Visual Data Cognitive adequacy is a fundamental requisite that effective visual systems need to realize. Making sense of visual data means to be able to represent their semantic content. Reproducing this capability at the machine level requires a comprehensive infrastructure where low–level perceptual and high–level cognitive processes couple with knowledge representations: for example, basic body movements and physical interactions such as e. g. , bending–over, extending–arm, holding, carrying (a manageable object for a given amount of time), etc."[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]

14. "McKeown {1985) deals extensively with cases of parallelism in text, although this account is not set in the context of a theory of coherence relations. Kittredge et al. {1991) give several examples of parallelism; indeed, in one case they identify ELABORATION as the relation responsible for the problem. Beyond elaboration 187 Nuclearity and embedding 3. 2 The preceding section presents a case where a 'context-free' theory of span structure undergenerates the space of possible texts."[Sanders, Ted, Joost Schilperoord, and Wilbert Spooren *Text representation: linguistic and psycholinguistic aspects*. John Benjamins Publishing Company, 2001.]

15. "In the following sections we focus on a particular cognitive architecture, ACT-R [5], introducing the general framework where ACT-R, integrated with a suitable knowledge resource, can adequately parse, disambiguate and describe visual information. 8. 2. 1 Mechanisms: Cognitive Architectures as Modules of Knowledge Production ACT-R is a modular system: its components include perceptual, motor and memory modules, synchronized by a procedural module through limited capacity buffers (see Fig."[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]