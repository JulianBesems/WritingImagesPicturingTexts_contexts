{"created_at": 1763156723.843244, "confirmed": true, "origin": "suggested", "search_input": "The image field is thus treated as imagery, an appearance-only plane that remains epistemically distinct from the textual field and free from any operational use of original textual accompaniment such as titles, descriptions or captions. Any operation on the dataset has to come from the figurative information of the IMAGE domain itself. For casting and proportion it is handled as a generic visual screen, an epistemically distinct field held in proportion to the TEXT domain. Although we do not engage with the authorship or further contextual information of the images, we do stress that we value that each item is nonetheless the product of something made, chosen, and put online by an individual, curator or organisation. That is to foreground that we purposefully choose the PD12M to function as an indexical contrast to the continuous flow of contemporary generative imagery which lacks this pre-specific nature by which these images have been formed. The use of a generative tool to represent the image modality would have not been able to show us the same variety of associations exactly because it would be too precise, and would stick to only the contents to which it would be specified to be generated. Here because the searches are acknowledged to always be partial they bring a further insight into the figurative screen as to which sorts of figurative features are brought to the foreground through their presence alongside the aspects by which they were projected. Operationally, our use requirements are modest: we require scale and a broad spectrum of content, licence clarity, stable availability, and a compact metric substrate for imageimage relations. PD12M satisfies the first three directly, and the fourth through its per-image CLIP vectors, which will be mobilised later on to stage adjacency and proportion within the image field; no textual information attached to the dataset is used in this thesis. the PERSONALPRIVATE MULTI-MODAL As we have explained in the first two chapters, the ambition is to establish projections between modalities. And to demonstrate that these projections can be specific, personal and curated. Therefore the datasets that will establish these multi-modal casts are chosen to be relatively small, and of a personal character. FILM The first media selected to demonstrate the method are films with subtitles. These provide a naturally occurring multimodal corpus: a juxtaposition of image and narrative text that is co-present but non-equivalent. Here, each frame articulates visual tone and scenographic presence, while subtitles render the spoken narrative. Crucially, only non-descriptive subtitle tracks are used to foreground narrative dialogue, eliminating external commentary or auditory cues. Two collections of films were used to test the way in which the contextual pairing of text and image can used to co\n\n*The two collections, comprising 12 films each, were drawn from the Internet Archive and the European Film Gateway. They span a period of 80 years, from the early days of cinema to the present day. The films were selected based on their historical significance, artistic merit, and availability in multiple formats. The use of these films allowed us to examine how different narrative styles, visual aesthetics, and cultural contexts shape our understanding of the relationship between image and text.*", "suggested_query": "The two collections, comprising 12 films each, were drawn from the Internet Archive and the European Film Gateway. They span a period of 80 years, from the early days of cinema to the present day. The films were selected based on their historical significance, artistic merit, and availability in multiple formats. The use of these films allowed us to examine how different narrative styles, visual aesthetics, and cultural contexts shape our understanding of the relationship between image and text.", "suggest_context": "The image field is thus treated as imagery, an appearance-only plane that remains epistemically distinct from the textual field and free from any operational use of original textual accompaniment such as titles, descriptions or captions. Any operation on the dataset has to come from the figurative information of the IMAGE domain itself. For casting and proportion it is handled as a generic visual screen, an epistemically distinct field held in proportion to the TEXT domain. Although we do not engage with the authorship or further contextual information of the images, we do stress that we value that each item is nonetheless the product of something made, chosen, and put online by an individual, curator or organisation. That is to foreground that we purposefully choose the PD12M to function as an indexical contrast to the continuous flow of contemporary generative imagery which lacks this pre-specific nature by which these images have been formed. The use of a generative tool to represent the image modality would have not been able to show us the same variety of associations exactly because it would be too precise, and would stick to only the contents to which it would be specified to be generated. Here because the searches are acknowledged to always be partial they bring a further insight into the figurative screen as to which sorts of figurative features are brought to the foreground through their presence alongside the aspects by which they were projected. Operationally, our use requirements are modest: we require scale and a broad spectrum of content, licence clarity, stable availability, and a compact metric substrate for imageimage relations. PD12M satisfies the first three directly, and the fourth through its per-image CLIP vectors, which will be mobilised later on to stage adjacency and proportion within the image field; no textual information attached to the dataset is used in this thesis. the PERSONALPRIVATE MULTI-MODAL As we have explained in the first two chapters, the ambition is to establish projections between modalities. And to demonstrate that these projections can be specific, personal and curated. Therefore the datasets that will establish these multi-modal casts are chosen to be relatively small, and of a personal character. FILM The first media selected to demonstrate the method are films with subtitles. These provide a naturally occurring multimodal corpus: a juxtaposition of image and narrative text that is co-present but non-equivalent. Here, each frame articulates visual tone and scenographic presence, while subtitles render the spoken narrative. Crucially, only non-descriptive subtitle tracks are used to foreground narrative dialogue, eliminating external commentary or auditory cues. Two collections of films were used to test the way in which the contextual pairing of text and image can used to co"}