<!doctype html>
<html lang="en"><head><meta charset="utf-8">
<title>Quote Context 5ca5330014eba5fa</title>
<style>
  body{font:14px/1.45 -apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:900px;margin:24px auto;padding:0 16px;color:#222}
  header{display:flex;gap:8px;align-items:center;margin-bottom:16px}
  .pill{padding:2px 8px;border-radius:999px;background:#f2f2f2;border:1px solid #e6e6e6;font-size:12px}
  h2{font-size:16px;margin:16px 0 8px}
  pre{white-space:pre-wrap;background:#fafafa;border:1px dashed #ddd;padding:8px;border-radius:8px}
  ol{margin:8px 0 0 20px}
  li.sel{background:#fff5cc}
  .selected{padding:8px 10px;border-left:4px solid magenta;background:#fff}
  .muted{color:#666;font-size:12px}
</style>
</head>
<body>
  <header>
    <div class="pill">ctx: 5ca5330014eba5fa</div>
    <div class="pill">origin: <strong style="color:magenta">suggested</strong></div>
  </header>

  <section>
    <h2>Search text used</h2>
    <pre>Figure 3.6:3 - Screenshot of 7 &quot;relevant word&quot; views of the image popup window. Figure 3.6:4 - Screenshot of the clicked word view on &quot;extracted&quot; of the image popup window, with the image labels that overlap with the query. Paragraph The second option is Paragraph. The signature is analogous: p rightarrow1 ptF rightarrow2 wfF rightarrow3 i The only difference being ptF instead of wtF: the writing is vectorised directly into the textual film space by fitting a TF-IDF matrix on the films subtitles and embedding p into that space with dimensionality corresponding to films. Because we do not differentiate words as inputs, we project ptF as a single vector onto the figurative domain; we then use all extracted regions from that activation as figurative sets for the image domain indexing regions by number. Each region marks a distinct figurative neighbourhood activated by the paragraph vector and yields its own image constellation. Figure 3.6:5 - Screenshot of 7 &quot;Paragraph&quot; views of the image popup window. Figure 3.6:6 - Screenshot of the clicked paragraph view on region 0 of the image popup window, with the image labels that overlap with the query. The regions are assembled to stage a scenography alongside the writing; not illustrations of it, but a backdrop and context. In practice, the prose navigates one textual field while, orthogonally, a visual field unfolds. This is our instrumented way of involving multiple domains while maintaining their differences. Serres, reading Leibniz, describes such contrapuntal analysis: Generally, the analysis is spun in such a way that several areas are involved at the same time: it is by this contrapuntal style that one recognises the master&#x27;s pen. This makes us understand why the overall system is always the horizon of each analysis: through successive multivalences, we move towards the whole. The unilinearity of the writing itself is thus overcome.. The operative image we seek to establish in this context is not a Cartesian chain but a network: &quot;since the image that Descartes and tradition have left us of their order is that of a chain, which concretises for the imagination the unity of progression and the connection of reasons, the image that imposes itself here is that of a network with several concurrent chains, which presents multiple &quot;entries&quot; and intersections: tapestry, weaving, embroidery or lace&quot;. This is why our image lists prefer complementarity over sameness: each constellation is composed to hold together scenographically rather than repeat a single motif. Where Batia Suter&#x27;s Parallel Encyclopedia traverses pictorial plenty through thematic clusters of depiction mediated by her personal observations, this setup approaches a collective visual reading via navigation by writing. As Suter notes on her method, &quot;Coincidence is like an instrument that can be played&quot;, which holds in our digital setup as well, where outcomes remain probabilistic rather than certain.

<em>The regions are assembled to stage a scenography alongside the writing; not illustrations of it, but a backdrop and context. Each region, then, can be seen as a distinct figurative neighbourhood, activated by the paragraph vector and yielding its own image constellation. By navigating the textual field, we can explore the visual field and vice versa, as the prose and images converse in a contrapuntal dance. This setup allows us to move towards the whole, overcoming the unilinearity of the writing itself and embracing the multivalences of the image lists. The operative image is that of a network, with multiple concurrent chains intersecting and weaving together to form a complex tapestry. Where Suter&#x27;s Parallel Encyclopedia presents a thematic clustering of depiction, our setup navigates by writing, yielding a collective visual reading. The outcomes remain probabilistic, as the instrument of coincidence is played in the digital realm. The image lists, composed of distinct figurative neighbourhoods, hold together scenographically, preferring complementarity over sameness. Each constellation is a unique visual reading, born from the intersection of writing and image.</em></pre>
  </section>

  <section>
    <h2>Selected</h2>
    <div class="selected">The brilliance of Klingemann’s identification of the content of the illustrations lies not in a reliance on a specific method, but on a combination of approaches. He employs multiple data clustering algorithms alongside a manual clustering of image training sets organised using human vision. The most prevalent method for making image content searchable, though, does not so much involve ‘vision’ as text. It is the spectral presence of words that haunt these various techniques, from the ‘Bag of Words’ model, and the textual metadata that underpins the pictures 3 SEARCHABILITY 39 retrieved from Google Images, to the crowdsourced tags in ImageNet that have been used in recent deep-learning experiments. 15 This dependence on words is a key component of large-scale databases containing illustrations that do not rely on computer vision, but instead use the surrounding text to ‘explain’ and return relevant images, whether this is the OCRed text (sometimes including the image caption), bibliographic and other metadata, or an amalgamation of different textual information.[(auth.), Julia Thomas *Nineteenth-Century Illustration and the Digital: Studies in Word and Image*. Palgrave Macmillan, 2017.]</div>
  </section>

  <section>
    <h2>All candidates <span class="muted">(right-click the quote in the editor to open this page)</span></h2>
    <ol>
      <li>&quot;The brilliance of Klingemann’s identification of the content of the illustrations lies not in a reliance on a specific method, but on a combination of approaches. He employs multiple data clustering algorithms alongside a manual clustering of image training sets organised using human vision. The most prevalent method for making image content searchable, though, does not so much involve ‘vision’ as text. It is the spectral presence of words that haunt these various techniques, from the ‘Bag of Words’ model, and the textual metadata that underpins the pictures 3 SEARCHABILITY 39 retrieved from Google Images, to the crowdsourced tags in ImageNet that have been used in recent deep-learning experiments. 15 This dependence on words is a key component of large-scale databases containing illustrations that do not rely on computer vision, but instead use the surrounding text to ‘explain’ and return relevant images, whether this is the OCRed text (sometimes including the image caption), bibliographic and other metadata, or an amalgamation of different textual information.&quot;[(auth.), Julia Thomas *Nineteenth-Century Illustration and the Digital: Studies in Word and Image*. Palgrave Macmillan, 2017.]</li>
<li>&quot;A representational image is deconstructed here to show the various compositional strategies—beyond the selection of subject and drawing medium—that the designer has considered in creating a well-resolved image. Each aspect of the composition reinforces the others. Mixing Image Styles As with all compositional strategies, creating contrast among visual elements is key to surprising, refreshing, and enlivening layouts—and this is no less true for imagery. Aside from the big-picture contrasts afforded by changing sizes, shapes, color, and spatial arrangement, combining different modes of image offers an important and highly effective method for introducing contrast.&quot;[Samara, Timothy *Design Elements: A Graphic Style Manual*. Rockport Publishers, 2007.]</li>
<li>&quot;Overall, this book argues for an intersection between the digital and illustration studies by drawing together these apparently distinct areas. Each chapter suggests how the concerns of the digital map onto the concerns of illustration studies and vice versa: the process of digital remediation and image processing is bound up in the visual identity of illustration (Chap. 2); the mechanisms for making image content searchable are intertwined with the politics of word and image (Chap. 3); and crowdsourced tagging is an activity that generates questions about what an ‘illustration’ is (Chap.&quot;[(auth.), Julia Thomas *Nineteenth-Century Illustration and the Digital: Studies in Word and Image*. Palgrave Macmillan, 2017.]</li>
<li>&quot;This relation is one that defines illustration, generates its meanings, and determines how it is viewed, yet it has received scant attention from critics. Lorraine Janzen Kooistra, one of the few scholars to examine the interaction between word and image in the context of illustration of the 1890s, remarks that ‘Although most studies of illustrated books pay lip service to the significant interactions of image and text, few critics have gone further to investigate just how these interactions work, or to theorize visual/verbal relationships’. 1 Kooistra proposes a notion of ‘bitextuality’ that accounts for the dialogue between word and image through an engagement with the sexualised discourse in which illustration is described.&quot;[(auth.), Julia Thomas *Nineteenth-Century Illustration and the Digital: Studies in Word and Image*. Palgrave Macmillan, 2017.]</li>
<li>&quot;The gap between the concrete idea and the ambiguously presented image that refers to it can provide more complex avenues of interpretation and a rich, engaging experience that yields deeper, more complex understanding. A jarring grid of checkered spaces gives way to a set of ellipses that change the pattern’s density to create type forms. The change also creates a strange, somewhat translucent quality and an ambiguous optical separation between the title and the background. Leonardo Sonnoli Italy Two conflicting grids—one for text, one for images—encourage bizarre overlaps of type and pictures, as well as linear elements, in this book spread.&quot;[Samara, Timothy *Design Elements: A Graphic Style Manual*. Rockport Publishers, 2007.]</li>
<li>&quot;The resulting surprise breathes life into the pacing among pages and highlights the content that is off the grid. Visual Logic Structuring the Page Intuitive Arrangement Integrating Type and Image Layout Systems COMPARE THE LOCATION of spatial breaks from left to right across this page spread with the grid diagram; although the majority of typographic and image content responds to the column structure, several items noticeably shift off the structure to introduce visual surprise and focus attention.&quot;[Samara, Timothy *Design Elements: A Graphic Style Manual*. Rockport Publishers, 2007.]</li>
<li>&quot;This is what Ricoeur calls an abstracted image, that is, an icon. In interpreting this specific line, the image can be visualized, and even &#x27;mapped&#x27; in a more or less literal sense, namely by visualizing a bare tree with black birds instead of fruits, or vice versa. 310 Thus, in reading this particular line, one may rely on the description of a concrete image that provides the basis for constructing an interpretation. We dwell on the image of black birds and fruit, and form an &#x27;icon&#x27; that captures the metaphorical predication in an almost visual representation.&quot;[Brouwer, Elisabeth Cathérine *Imagining Metaphors: Cognitive Representation in Interpretation and Understanding*. Institute for Logic, Language and Computation Universiteit van Amsterdam, 2003.]</li>
<li>&quot;Even when a visual reference is fairly direct, unnecessary embellishment of the image (c) can distract if it evokes additional, undesired associations. The Label icon above, for example, seems more like a price tag, or ticket, while the Scrolled Text icon, thanks to its dog-eared paper element, misleadingly suggests a file- or document-level operation 196 Image and Representation n n FAULTS (a) SCREEN ^ V r ^ w1 (b) (g&gt; (d) &lt;e) (f) ww—i ^ fr (c) 217: Culture or language dependencies. The pragmatic aspect of an image describes assumptions about the viewer and the viewing environment that are implicit in any visual representation.&quot;[Mullet, Kevin, and Darrell Sano *Designing Visual Interfaces: Communication Oriented Techniques*. Prentice Hall, 1994.]</li>
<li>&quot;The algorithmic part of their work lies in establishing a hierarchical representation of the image and the subsequent abstraction of the image based on the acquired user attention data. To execute these tasks, ﬁrst the target image is segmented into multiple regions, from which a pyramid representation of the image is later constructed based on the hierarchical structure suggested by the containment relationships of regions. Such a containment relationship is justiﬁed by the scale-space theory [Lin94] and computed through performing image segmentation on various scales.&quot;[Xu, Songhua, Francis C.M. Lau, and Yunhe Pan *A Computational Approach to Digital Chinese Painting and Calligraphy*. Springer, 2009.]</li>
<li>&quot;[Bro07] Stephen Brooks. Mixed media painting and portraiture. IEEE Transactions on Visualization and Computer Graphics, 13 (5):1041–1054, 2007. [BS98] Sean Borman and Robert L. Stevenson. Super-resolution from image sequences—a review. In MWSCAS ’98: Proceedings of the 1998 Midwest Symposium on Systems and Circuits, Notre Dame, IN, USA: IEEE Computer Society, page 374, 1998. [BY97] Michael J. Black and Yaser Yacoob. Recognizing facial expressions in image sequences using local parameterized models of image motion.&quot;[Xu, Songhua, Francis C.M. Lau, and Yunhe Pan *A Computational Approach to Digital Chinese Painting and Calligraphy*. Springer, 2009.]</li>
<li>&quot;The geometric relation between the concurrent motions of just two forms as in Figure Seeing 455 2C is not generally sufficient to specify the perspective transformation that has yielded the observed spatio-temporal image. By the fundamental theorem of plane perspectivity (Delone, 1963), the perspective mapping of four points in general position (where no three points are collinear) in one image plane onto a corresponding set of four points in another image plane is necessary and sufficient to ensure that all of the remaining points are in isometric correspondence in the two planes.&quot;[Kaiser, Mary K., Arthur C. Grunwald, and Stephen R. Ellis *Pictorial communication in virtual and real environments*. London: New York, Taylor &amp; Francis, 1991.]</li>
<li>&quot;He used the printer’s camera to alter images and explored the unique properties of the film image. Weingart began to move away from purely typographic design and embraced collage as a medium for visual communication (Fig. 22–14). A new technique—the sandwiching or layering of images and type that have been photographed as film positives—enabled him to overlap complex visual information (Fig. 22–15), juxtapose textures, and unify typography in unprecedented ways. He took particular delight in the graphic qualities of enlarged halftone dots (Fig.&quot;[Meggs, Philip B., and Alston W. Purvis *Meggs’ History of Graphic Design, 5th Edition*. 5th ed. Wiley, 2011.]</li>
<li>&quot;So in general, even single images require background knowledge on motion processes in space for more in-depth understanding; this is often overlooked in machine or computer vision. The approach discussed in this book (bold italic letters in Figure 1. 1) takes motion processes in “3-D space and time” as basic knowledge required for understanding image sequences in an approach similar to our own way of image interpretation. This yields a natural framework for using language and terms in the common sense.&quot;[Dickmanns, Ernst Dieter *Dynamic Vision for Perception and Control of Motion*. London: Springer, 2007.]</li>
<li>&quot;Thus, for a set of four or more points in a single plane, the concurrent motions of the images of these points in another plane seem to be sufficient in principle to specify the perspective transformation between these two planes and to specify the metric structure of the spatial relations within these planar images. This geometric relationship endows spatial as well as moving images with considerable capacity for carrying information about the geometric structure of the environmental surfaces depicted in the images: the geometric structure of an infinitesimally small patch on any arbitrarily curved but smooth surface may be locally approximated by a tangent plane at that location, and the perspective mapping of this tangent plane onto an image plane may be described by a linear coordinate transformation.&quot;[Kaiser, Mary K., Arthur C. Grunwald, and Stephen R. Ellis *Pictorial communication in virtual and real environments*. London: New York, Taylor &amp; Francis, 1991.]</li>
<li>&quot;Contrary to perspective mapping in a single image (in which depth information is completely lost), the partial first-order derivatives of each feature with respect to all variables affecting its appearance in the image do contain spatial information. Therefore, linking the temporal motion process in 4-D with this physically meaningful Jacobian matrix has brought about a quantum leap in visual dynamic scene understanding [Dickmanns, Meissner 1983, Wünsche 1987, Dickmanns 1987, Dickmanns, Graefe 1988, Dickmanns, Wuensche 1999].&quot;[Dickmanns, Ernst Dieter *Dynamic Vision for Perception and Control of Motion*. London: Springer, 2007.]</li>
    </ol>
  </section>
</body></html>
