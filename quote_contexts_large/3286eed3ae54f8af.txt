Created: 2025-12-18 22:43:00
Origin: suggested
Selected: 12 4 DEDRE GENTNER AND BRIAN BOWDLE Notes 1 2 3 4 5 6 Although structure-mapping is best known as a theory of analogy, metaphor has been a focus of the work from its inception (e. g. , Gentner, 1982). Structure-mapping theory assumes the existence of structured representations made up of entities and their attributes, functions that map entities to dimensions or to other entities, relations between objects, and higherorder relations between relations. This discussion is taken chiefly from structure-mapping theory (Gentner, 1983 ; Gentner & Markman, 1997) and its computational model, SME, the structure-mapping engine (Falkenhainer, Forbus, & Gentner, 1989; Forbus, Gentner, & Law, 1995 ; Forbus & Oblinger, 1990).[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

--- Context List ---
01. "12 4 DEDRE GENTNER AND BRIAN BOWDLE Notes 1 2 3 4 5 6 Although structure-mapping is best known as a theory of analogy, metaphor has been a focus of the work from its inception (e. g. , Gentner, 1982). Structure-mapping theory assumes the existence of structured representations made up of entities and their attributes, functions that map entities to dimensions or to other entities, relations between objects, and higherorder relations between relations. This discussion is taken chiefly from structure-mapping theory (Gentner, 1983 ; Gentner & Markman, 1997) and its computational model, SME, the structure-mapping engine (Falkenhainer, Forbus, & Gentner, 1989; Forbus, Gentner, & Law, 1995 ; Forbus & Oblinger, 1990)."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

02. "Such structure yields complexity beyond that typically shown in co-speech gestures or the binding of text with individual images (Cohn, 2013a). This work seeks to characterize such complex multimodal interactions by expanding on Jackendoff’s (2002) parallel architecture for language. Here, focus will be placed on how grammar and meaning coalesce in multimodal interactions, extending beyond the semantic taxonomies typically discussed about text–image relations (e. g. , Kress, 2009; Martinec & Salway, 2005; McCloud, 1993; Royce, 2007)."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

03. "Fig. 13. Step-by-step method for analysis of multimodal interactions. 320 N. Cohn / Cognition 146 (2016) 304–323  (e. g. , Cimermanová, 2015; Mayer, 2009), despite its importance. To this point, this overall parallel architecture emphasizes both the structures involved in behaviors, but also the interfaces linking these structures. This is especially important when considering development, both for monomodal and multimodal information, since fluency in a structure requires an interface between structures, not just the structure itself."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

04. "This approach can instead involve “metaphorizing” the literal sentences in the relevant discourse segment: translating the information in them into sourcedomain terms. We present this possibility as a potentially fruitful topic for future research into metaphor. Conclusion AI is not just about the engineering of “intelligent” artefacts for useful purposes but also about mapping out the space of possible principles and mechanisms of cognition, whether artificial or natural."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

05. "AI is in a peculiar position to add both to the appreciation of the variety and complexity of metaphor as it arises in practical discourse and to the question of how to process real metaphor in practical contexts, because of the inclusion within AI of applications-oriented research. One of the AI systems reviewed above (MIDAS, by James Martin) concentrated on metaphor arising in question-and-answer sessions between users and an automated Unix help system."[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]

06. "The topic of the main Section 2 is a discussion of ontological and methodological aspects of contrastive information structure analysis. Section 2 also contains some relativising remarks on the ideal methodological requirements on contrastive information structure analysis as discussed before. The point here is that keeping this ideal in mind and explaining in how far a prospective instance of contrastive information structure analysis matches it is more fruitful than not undertaking the analysis in the first place just because it may be impossible to heed the ideal completely."[Breul, Carsten, and Edward Göbbel *Comparative and Contrastive Studies of Information Structure*. John Benjamins Publishing Company, 2010.]

07. "This notion can be extended to many text–image relations as well (Cohn, 2013a), where bundled text and image form a coherent message within a single panel that progresses to subsequent units (e. g. , McCloud, 1993). In both cases, modalities may make a semantic correspondence in relating to common conceptual information (McNeill, 1992), but the visual-graphic domain does not use temporal correspondence as in co-speech gesture (i. e. , association from occurring at the same time) unless it is produced in real time interactions (e. g. , Green, 2014)."[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]

08. "The VERL approach does not refer to large–scale domain ontologies or to acknowledged patterns to provide a structure to the event models. Ballan et al. use the hierarchical linguistic relations over lexical entries encoded in WordNet to learn and refine rules that detect complex events from simple ones [3]. An ontology-based approach to the detection and annotation of events is video is pursued also by the 116 M. Cataldi et al. Mind’s Eye project [10]. In this work, the events detected in video are described as “verbs”, described in terms of a spatial model of motion."[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]

09. "In the desired framework, visual intelligent systems should be able to reconstruct a “story” from basic information, blending relevant visual data with common-sense knowledge into a unifying conceptual pattern. Adopting an architectural perspective, implementing this capability would require three different strata of information elaboration: basic optical features (low-level), object detection (mid-level) and event classification (high-level). In this contribution we focus on high-level mechanisms and contents, namely the core visual intelligence as opposed to state-of-the-art machine vision."[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]

10. "The compositional structure claimed for SF is very much in line with the proposals of lackendoff (1983, 1987, and chapter I, this volume) about conceptual structure (CS), with one important difference, however, which has consequences for the relation of language and space. The problem is this. Although what lackendoff calls "lexical conceptual structure" (LCS) is-details aside-very close in spirit to the SF information SF(le) of lexical items, he explicitly claims that conceptual structure (CS; and hence LCS) is an extralinguistic level of representation."[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]

11. "However, another basic concept in CA, i. e. social action, has not been fully addressed. An account of linguistic features of turn design may provide us with a point of departure to explore how social actions are formed through different turn designs. Curl and Drew’s (2008) illuminating research shows that the two different forms of syntactic structures (i. e. “Can you…?” and “I wonder if…?”) form two types of requesting actions in different contexts. Drew (2010) also addresses ascription of action through analyzing the linguistic design of turns."[Li, Xiaoting *Multimodality, Interaction and Turn-taking in Mandarin Conversation*. John Benjamins Publishing Company, 2014.]

12. "By analogy with O’Halloran’s (1999) semiotic metaphor, we propose to analyze the motivated patterning across modes in terms of “semiotic foregrounding. ” As far as the analysis in this chapter is concerned, this means that the level of multimodal symbolic articulation has to take account of three types of foregrounding: verbal foregrounding, visual foregrounding, and semiotic foregrounding."[Webster, Jonathan J., and Xuanwei Peng (eds.) *Applying Systemic Functional Linguistics: The State of the Art in China Today*. Bloomsbury Academic, 2017.]

13. "The uses illustrated above exploit the cognitive association between a change o f physical orientation (through rotation) and a change of state. By contrast, an example such as T he talk turned to fo o d derives from the notion of trajectory change (the talk did not turn into food but changed direction). There are two metaphors at work here. The underlying metaphor, ‘Conversation is a journey’, is a prerequisite for the superimposed metaphor of change of topic as change of direction."[David., Lee *Cognitive linguistics: an introduction*. 2017.]

14. "Then, we gave an introduction to the pdtb browser, which gives access to discourse relation annotation of the Penn Discourse Treebank. Finally, we rounded off the chapter by providing an overview of Annis, a multi-purpose search and visualization tool that captures syntactic annotation as well as coreference and discourse annotation. 270 9781441164476_txt_print. indd 270 02/10/2014 09:41 Searching for Semantic and Discourse Phenomena 13. 5â•‡ Further Reading Section 13. 1 Frame Index: The index of semantic frames is accessible at https://framenet. icsi. berkeley."[Kuebler, Sandra, and Heike Zinsmeister *Corpus Linguistics and Linguistically Annotated Corpora*. annotated edition. Bloomsbury Academic, 2015.]

15. "In this respect, accessibility theory resembles recent attempts to reduce some anaphora phenomena to pragmatic principles, such as Reinhart (1983), Kempson (1984), Levinson (1987, 1991), Huang {1994), Gundel et al. (1993), and Ward et al. (1991). One Accessibility theory could then suggest that accessibility theory should be formulated as a set of extralinguistic inferences, connecting between linguistic forms and proper contexts on the basis of common sense inferences from their semantic meanings, rather than based on conventional form-function correlations (see Reboul 1997; Bach 1998)."[Sanders, Ted, Joost Schilperoord, and Wilbert Spooren *Text representation: linguistic and psycholinguistic aspects*. John Benjamins Publishing Company, 2001.]