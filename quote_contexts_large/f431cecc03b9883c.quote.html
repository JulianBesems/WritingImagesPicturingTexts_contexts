<!doctype html>
<html lang="en"><head><meta charset="utf-8">
<title>Quote Context f431cecc03b9883c</title>
<style>
  body{font:14px/1.45 -apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;max-width:900px;margin:24px auto;padding:0 16px;color:#222}
  header{display:flex;gap:8px;align-items:center;margin-bottom:16px}
  .pill{padding:2px 8px;border-radius:999px;background:#f2f2f2;border:1px solid #e6e6e6;font-size:12px}
  h2{font-size:16px;margin:16px 0 8px}
  pre{white-space:pre-wrap;background:#fafafa;border:1px dashed #ddd;padding:8px;border-radius:8px}
  ol{margin:8px 0 0 20px}
  li.sel{background:#fff5cc}
  .selected{padding:8px 10px;border-left:4px solid magenta;background:#fff}
  .muted{color:#666;font-size:12px}
</style>
</head>
<body>
  <header>
    <div class="pill">ctx: f431cecc03b9883c</div>
    <div class="pill">origin: <strong style="color:magenta">suggested</strong></div>
  </header>

  <section>
    <h2>Search text used</h2>
    <pre>Instead of relying on computation to collect and internalise all modes of representation in a single relation, this thesis is concerned with how we create talks between them on a level of abstraction that doesnt define the outcome as a linear result of the base. We regard the 3D model as one member of a multimodal ensemble: indispensable where geometry is at stake, yet insufficient as the locus of architectural knowledge. To arrive at a setup that allows for this other aspect, we focus on modalities that currently dominate digital multimodality - text and image - because contemporary machine learning models operate most powerfully across these domains. As an alternative approach to mediate between modes of communications, computational processes are tuned to offer means of projecting between domains in non-systematic matters: focussing on association and on navigating the digital plenty that we have at our disposal. This proposes a non-linear model that facilitates the communication between domains, maintaining a proportionality. Focussed on facilitating an understanding. These associations are approached as invitations into conversation. As stated by Valry, as soon as we make a comparison it is not moving and we are not entering the relation between the objects. Comparison communicates through distance, difference, and proximity; it tends to stabilise. Instead of focussing only on what is close and similar, the scope here is to explore a means of association that forms constellations, what Ishigami calls an approachable abstraction. These constellations are treated as indefinite and ambiguous clusters of things that might engage in talks, much like the Kunstkammer as discussed by Horst Bredekamp. Within this context, machine learning ML is approached less as an means of classification or generation, and more as a family of techniques that enable projections within domains and between domains. Examples range from self-organising maps SOM to contemporary textimage systems. Although these projections rest on encoding domains into vectors between which distances can be measured the relations they establish do not behave like a single explicit function that can be written down in advance. Using ML methods, the projection from a domain to a co-domain follows contingent relations established through associations of data. Removing a strictly linear connection between domain and co-domain has the potential to lift the resulting architectonic connection out of geometry onto a communication between non-commensurable fields. This does not mean abandoning geometry; rather it means resisting its monopolisation. It will rely on discerning proportionalities between domains instead of translating them into the same common set, comparable to the proportion between plan and section. These domains in architecture are not the same, nor can they be reduced to one field; they need to stand orthogonal to each other to bear meaning. Within that scope, we treat ML as a non-systematic means of orienting qualitative data: facilitating projections within and between domains that do not follow a pre-declared mathematical function, and thereby tuning indefinite and ambiguous constellations of communication.

<em>This approach does not eliminate the necessity of geometry, but rather complements it with other modalities that can capture the complexity of architectural knowledge. By acknowledging the limits of geometry, we can start to think about how to negotiate between different domains and their respective modes of representation. For instance, the text-based modality can be used to describe the spatial layout of a building, while the image-based modality can be used to convey the aesthetic and visual aspects of the architecture. By tuning these modalities together, we can create a more comprehensive understanding of the architecture.</em></pre>
  </section>

  <section>
    <h2>Selected</h2>
    <div class="selected">Contrasting, for example, record and circle, we notice that circle is part of the shape information in record, which relies, however, on knowledge explaining sound storage (in varying degrees of detail), while nothing (beyond mere geometry) is explained by circle. For almost trivial reasons, the distinction of rich and spare concepts relates to (but is not identical with) the distinction between extrinsic and intrinsic spatial concepts, as opposed to strictly spatial concepts.[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]</div>
  </section>

  <section>
    <h2>All candidates <span class="muted">(right-click the quote in the editor to open this page)</span></h2>
    <ol>
      <li>&quot;Contrasting, for example, record and circle, we notice that circle is part of the shape information in record, which relies, however, on knowledge explaining sound storage (in varying degrees of detail), while nothing (beyond mere geometry) is explained by circle. For almost trivial reasons, the distinction of rich and spare concepts relates to (but is not identical with) the distinction between extrinsic and intrinsic spatial concepts, as opposed to strictly spatial concepts.&quot;[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]</li>
<li>&quot;In these cases, expressing the location in text rather than images may allow for a more economical message (less panels), but may lead the content of each domain to convey different aspects of meaning, and thereby require the integration of novel information across multiple sources (e. g. , Fauconnier &amp; Turner, 2002). A related process occurs in the substitutive example in Fig. 7b, since the Peak is represented by text instead of an image. Other examples of absorption are discussed at length by Stainbrook (2003, 2015) who describes how surface cohesive relations between images and text contribute toward a holistic mental model of a multimodal discourse (e. g. , van Dijk &amp; Kintsch, 1983), and comparable notions are echoed in Painter et al. ’s (2012) discussion of text or images ‘‘committing” different amounts to a global meaning.&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;Conceptual representation of spatial structure provides, among other things, more abstract schemata specifying the dimensionality of objects and situations, the axes and frames of reference of their location, and metrical scales with respect to which size is determined. 3. Linguistic knowledge or I-language interfaces with conceptual structure, recruiting configurations of it by basic components of semantic form, where strictly spatial concepts are to be identified as configurations that interpret elements of SF by exclusively spatial conditions on objects and situations.&quot;[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]</li>
<li>&quot;However, visual narratives, like those in comics, provide an interesting challenge to multimodal communication because the words and/or images can guide the overall meaning, and both modalities can appear in complicated ‘‘grammatical” sequences: sentences use a syntactic structure and sequential images use a narrative structure. These dual structures create complexity beyond those typically addressed by theories of multimodality where only a single form uses combinatorial structure, and also poses challenges for models of the linguistic system that focus on single modalities.&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;Such structure yields complexity beyond that typically shown in co-speech gestures or the binding of text with individual images (Cohn, 2013a). This work seeks to characterize such complex multimodal interactions by expanding on Jackendoff’s (2002) parallel architecture for language. Here, focus will be placed on how grammar and meaning coalesce in multimodal interactions, extending beyond the semantic taxonomies typically discussed about text–image relations (e. g. , Kress, 2009; Martinec &amp; Salway, 2005; McCloud, 1993; Royce, 2007).&quot;[INPUT: Cohn - 2016 - A multimodal parallel architecture A cognitive framework for multimodal interactions.pdf]</li>
<li>&quot;Nevertheless, multimodal texts pose challenges to this notion, as the architecture of a multimodal text consists of several sets of components, which means that contrast and comparison across modes have to be included in stylisticians’ agendas to ﬁnd out foregrounding across modes. In fact, studies on intersemiotic relations in multimodal discourse analysis have proposed several terms to account for multimodal construal of meaning in multimodal texts: namely, “resemioticization” (Iedema 2003: 30), “multiplication of meaning” (Lemke 1998), “semiotic metaphor” (O’Halloran 1999), and “translation” (Kress and van Leeuwen 2006: 78).&quot;[Webster, Jonathan J., and Xuanwei Peng (eds.) *Applying Systemic Functional Linguistics: The State of the Art in China Today*. Bloomsbury Academic, 2017.]</li>
<li>&quot;In the desired framework, visual intelligent systems should be able to reconstruct a “story” from basic information, blending relevant visual data with common-sense knowledge into a unifying conceptual pattern. Adopting an architectural perspective, implementing this capability would require three different strata of information elaboration: basic optical features (low-level), object detection (mid-level) and event classification (high-level). In this contribution we focus on high-level mechanisms and contents, namely the core visual intelligence as opposed to state-of-the-art machine vision.&quot;[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]</li>
<li>&quot;12 4 DEDRE GENTNER AND BRIAN BOWDLE Notes 1 2 3 4 5 6 Although structure-mapping is best known as a theory of analogy, metaphor has been a focus of the work from its inception (e. g. , Gentner, 1982). Structure-mapping theory assumes the existence of structured representations made up of entities and their attributes, functions that map entities to dimensions or to other entities, relations between objects, and higherorder relations between relations. This discussion is taken chiefly from structure-mapping theory (Gentner, 1983 ; Gentner &amp; Markman, 1997) and its computational model, SME, the structure-mapping engine (Falkenhainer, Forbus, &amp; Gentner, 1989; Forbus, Gentner, &amp; Law, 1995 ; Forbus &amp; Oblinger, 1990).&quot;[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]</li>
<li>&quot;According to this theory, sequences of musical events produce brain maps that can be correlated with brain maps produced by other modalities (including vision, taste, and proprioception); these correlations then operate as symbols to form the basis for conceptual knowledge. The array of perceptual symbols (or image schemata) that may be used to structure a given relationship is potentially quite extensive; cultural knowledge provides one constraint on which structures are chosen.&quot;[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]</li>
<li>&quot;However, as discussed later, linguistic metaphor as a whole fits as a category within the framework of general fictivity. General fictivity can serve as the superordinate framework because, among other reasons, its concepts and terms can apply as readily to visual representations as to linguistic ones, whereas metaphor theory is cast in concepts and terms more suitable for language alone. Using the perspective and methods of cognitive linguistics, the present study of fictive motion is based in language, but extends out from there to considerations of visual perception.&quot;[P., Bloom, Peterson M.A., Nadel L., and Garret M.F. (eds.) *Language and Space*. 2017.]</li>
<li>&quot;Instead, a whole analogical structure must be generated that may have many different correspondences and alignments. 1 There are models of analogy making that can deal with complex structures, for example, like mapping the solar system into atomic structure. Such models (e. g. , Forbus, Gentner, &amp; Law, 1995 ; Hummel &amp; Holyoak, 1997) can perform more complex mappings than the present model. However, because they rely on hand-coded propositional knowledge representations, they circumvent an essential component of the comprehension process, the construction of the problem- 141 relevant knowledge representation, which is the focus of the present approach.&quot;[Jr., Raymond W. Gibbs *The Cambridge Handbook of Metaphor and Thought*. New York: Cambridge University Press, 2008.]</li>
<li>&quot;Vice versa, “verbal metaphor itself often elicits references to visual, aural, tactile, and olfactory experiences. ” From the point of view of language use this suggests that there is perhaps a functional link between metaphoric structure and the format of a “subject’s encyclopedia. ” As Eco puts it, “metaphors are produced solely on the basis of a rich cultural framework. ”14 A directional theory of meaning welcomes this kind of analysis because it draws our attention to the question of the linking procedures which we are forced to assume exist between verbal and non-verbal signification.&quot;[Ruthrof, Horst *Pandora and Occam: on the limits of language and literature*. Routledge, 2017.]</li>
<li>&quot;The next sections present the Cognitive Engine, an integrated artificial system whose architectural characteristics, operational capabilities and knowledge resources are designed to approximate the cognitive machinery of visual intelligence. 8. 3 Making Sense of Visual Data Cognitive adequacy is a fundamental requisite that effective visual systems need to realize. Making sense of visual data means to be able to represent their semantic content. Reproducing this capability at the machine level requires a comprehensive infrastructure where low–level perceptual and high–level cognitive processes couple with knowledge representations: for example, basic body movements and physical interactions such as e. g. , bending–over, extending–arm, holding, carrying (a manageable object for a given amount of time), etc.&quot;[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]</li>
<li>&quot;McKeown {1985) deals extensively with cases of parallelism in text, although this account is not set in the context of a theory of coherence relations. Kittredge et al. {1991) give several examples of parallelism; indeed, in one case they identify ELABORATION as the relation responsible for the problem. Beyond elaboration 187 Nuclearity and embedding 3. 2 The preceding section presents a case where a &#x27;context-free&#x27; theory of span structure undergenerates the space of possible texts.&quot;[Sanders, Ted, Joost Schilperoord, and Wilbert Spooren *Text representation: linguistic and psycholinguistic aspects*. John Benjamins Publishing Company, 2001.]</li>
<li>&quot;In the following sections we focus on a particular cognitive architecture, ACT-R [5], introducing the general framework where ACT-R, integrated with a suitable knowledge resource, can adequately parse, disambiguate and describe visual information. 8. 2. 1 Mechanisms: Cognitive Architectures as Modules of Knowledge Production ACT-R is a modular system: its components include perceptual, motor and memory modules, synchronized by a procedural module through limited capacity buffers (see Fig.&quot;[Oltramari, Alessandro, Piek Vossen, Lu Qin (auth.), Alessandro Oltramari, Piek Vossen, Lu Qin, and Eduard Hovy (eds.) *New Trends of Research in Ontologies and Lexical Resources: Ideas, Projects, Systems*. Springer-Verlag Berlin Heidelberg, 2013.]</li>
    </ol>
  </section>
</body></html>
